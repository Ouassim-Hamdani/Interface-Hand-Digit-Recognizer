<!DOCTYPE html><html><head>
      <title>report</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\Ouassim\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.14\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="super-handwritten-digit-recognition">Super Handwritten Digit Recognition </h1>
<p><strong>Project by:</strong> Ouassim HAMDANI</p>
<p><strong>Class:</strong> Master 1 IIA -  Multi-source Data Extraction</p>
<p><strong>Date:</strong> November 5, 2024</p>
<h2 id="1-introduction">1. Introduction </h2>
<p>This project focuses on the classic problem of handwritten digit recognition. The goal is to develop a machine learning model capable of accurately classifying images of handwritten digits (0-9). This task has numerous real-world applications, including:</p>
<ul>
<li><strong>Automated mail sorting:</strong> Reading handwritten zip codes on envelopes.</li>
<li><strong>Check processing:</strong> Recognizing handwritten digits on checks.</li>
<li><strong>Form data entry:</strong>  Automating the digitization of handwritten forms.</li>
</ul>
<p>This report details the process of building and evaluating a model for this task using the MNIST dataset.</p>
<h2 id="2-problem-statement">2. Problem Statement </h2>
<p>The problem addressed in this project is a <strong>multi-class classification</strong> problem. Given an image of a handwritten digit, the model must assign it to one of ten classes (0, 1, 2, ..., 9).  This project utilizes the data and problem definition from the Kaggle competition "Digit Recognizer" (<a href="https://www.kaggle.com/c/digit-recognizer">link to Kaggle competition</a>).</p>
<h2 id="3-dataset">3. Dataset </h2>
<p>The dataset used for this project is the <strong>MNIST</strong> (Modified National Institute of Standards and Technology) dataset, a widely used benchmark in computer vision. It consists of <strong>42,000</strong> grayscale images of handwritten digits (0-9).</p>
<p>Each image is <code>28x28</code> pixels, with each pixel representing a grayscale value from 0 (white) to 255 (black). The training data includes labels indicating the correct digit for each image.</p>
<p><strong>Data Format:</strong></p>
<p>The data is provided in CSV (Comma Separated Values) format, found in <code>Data</code> Folder.</p>
<ul>
<li><strong>train.csv:</strong> Contains 785 columns.
<ul>
<li><code>label</code>: The first column, representing the digit (0-9).</li>
<li><code>pixel0</code> to <code>pixel783</code>: The remaining columns, representing the pixel values of the 28x28 image.</li>
</ul>
</li>
<li><strong>test_gen.csv:</strong>  Similar to <code>train.csv</code>, splitted from training set, used to evaluate model on data never seen before.</li>
</ul>
<p><strong>Pixel Representation:</strong></p>
<p>The pixels in the images are stored in row-major order. For example, <code>pixel31</code> corresponds to the pixel at row 1, column 3 of the 28x28 image matrix (using zero-based indexing).</p>
<p><strong>Visualization of Some Sampless:</strong></p>
<p><img src="figures/samples.png" alt=""></p>
<p><strong>Classes Balanace :</strong></p>
<p><img src="figures/classes.png" alt="alt text"></p>
<h2 id="4-data-preprocessing">4. Data Preprocessing </h2>
<p>The following preprocessing steps were applied to the data:</p>
<ul>
<li><strong>Splitting:</strong> The data was split into training and testing sets using an 80/20 ratio.</li>
<li><strong>Reshaping:</strong> The image data (pixel values) was reshaped from a flat vector of 784 pixels to a 28x28x1 matrix to represent the image structure.</li>
<li><strong>Padding:</strong>  The images were padded to 32x32 pixels to be compatible with the input requirements of the pre-trained models (VGG19 and ResNet50).</li>
<li><strong>Channel Duplication:</strong> The grayscale images (1 channel) were duplicated to have 3 channels, which is necessary for the pre-trained models.</li>
<li><strong>Normalization:</strong> (Optional)  Pixel values were normalized to a range of 0-1 to improve model training.</li>
</ul>
<h2 id="5-model-selection">5. Model Selection </h2>
<p>Two pre-trained models were selected for this project alongside a trained CNN:</p>
<ul>
<li><strong>VGG19:</strong> A deep convolutional neural network with 19 layers, known for its good performance in image classification tasks.</li>
<li><strong>ResNet50:</strong> A 50-layer residual network that uses skip connections to address the vanishing gradient problem, allowing for the training of very deep networks.</li>
<li><strong>CNN:</strong> A convolutional neural network with three convolutional layers, each followed by a max-pooling layer, for feature extraction. The extracted features are then flattened and passed through two dense layers for classification.</li>
</ul>
<p>These models were chosen due to their proven effectiveness in image recognition and their availability in Keras. CNN model was trained, and the other models were fine-tuned by:</p>
<ul>
<li><strong>Removing the top layers:</strong> The original classification layers of the pre-trained models were removed, as they are specific to the ImageNet dataset.</li>
<li><strong>Adding new layers:</strong> New fully connected layers were added to adapt the models to the MNIST dataset and the 10-class classification task.</li>
<li><strong>Freezing layers:</strong> Most Layers in the  VGG19 pre-trained model were frozen to prevent their weights from being updated during training, but for the case of ResNET50, all layers were finetunned (retrained), for better task adaptation.</li>
</ul>
<h2 id="6-model-training">6. Model Training </h2>
<p>The models were trained using the following settings:</p>
<ul>
<li><strong>Optimizer:</strong> Adam optimizer with a learning rate of <code>0.001</code>.</li>
<li><strong>Loss function:</strong> Sparse categorical cross-entropy, suitable for multi-class classification.</li>
<li><strong>Metrics:</strong> <code>Accuracy</code> was used, as the data classes were good balanced.</li>
<li><strong>Data augmentation:</strong> <code>ImageDataGenerator</code> was used to augment the training data with random rotations, shifts, and shears to improve model generalization.</li>
<li><strong>Epochs:</strong> The models were trained for 50 epochs.</li>
<li><strong>Batch size:</strong> A batch size of 200 was used.</li>
</ul>
<p><strong>Training History:</strong></p>
<p>The following plots illustrate the training and validation accuracy and loss over epochs:</p>
<p><strong>VGG 19 Training Figures</strong></p>
<p><img src="figures/model_vgg_acc.png" alt=""></p>
<p><img src="figures/model_vgg_loss.png" alt=""></p>
<p><strong>ResNET50 Training Figures</strong></p>
<p><img src="figures/model_resnet_acc.png" alt=""></p>
<p><img src="figures/model_resnet_loss.png" alt=""></p>
<p><strong>CNN Model Training Figures</strong></p>
<p><img src="figures/model_cnn_acc.png" alt=""></p>
<p><img src="figures/model_cnn_loss.png" alt=""></p>
<p>No large overfitting was detected, thus no need for L1, L2 regulization, or dropout method.</p>
<h2 id="7-model-evaluation">7. Model Evaluation </h2>
<ul>
<li>
<p><strong>VGG19:</strong> Achieved an accuracy of <code>97.67%</code> on the test set. (Max was <code>98.7%</code> when all layers were fully trained, we stayed with the first result)</p>
</li>
<li>
<p><strong>ResNet50:</strong> Achieved an accuracy of <code>98.05%</code> on the test set.</p>
</li>
<li>
<p><strong>CNN Model:</strong> Achieved an accuracy of <code>99.10%</code> on the test set.</p>
</li>
</ul>
<h2 id="8-model-ensembling">8. Model Ensembling </h2>
<p>To further improve performance, the models were ensembled by averaging their predictions. This resulted in an accuracy of <strong>99.20%</strong> on the test set.</p>
<h2 id="9--analysis-of-errors">9.  Analysis of Errors </h2>
<p>A confusion matrix was generated to analyze the types of errors made by the ensembled model. It revealed that the most common confusion was between digits similiar in handwritten shape (8,9) (1,7)...etc, which is understandable as these digits can have similar appearances in handwritten form.</p>
<p><img src="figures/cm.png" alt=""></p>
<p><strong>Visualizations of some predictions made by model :</strong></p>
<p><img src="figures/preds.png" alt=""></p>
<h2 id="10-conclusion">10. Conclusion </h2>
<p>This project successfully demonstrated the effectiveness of transfer learning and model ensembling for handwritten digit recognition. By fine-tuning pre-trained VGG19 and ResNet50 models alongside training a full CNN model, and combining their predictions, a high accuracy of <code>99.20%</code> was achieved on the MNIST dataset.</p>
<p><strong>Potential improvements (Why not?):</strong></p>
<ul>
<li><strong>Hyperparameter tuning:</strong> Explore different hyperparameter settings (e.g., learning rate, number of layers added, batch size) to potentially improve performance.</li>
<li><strong>Different architectures:</strong> Experiment with other pre-trained models or custom CNN architectures.</li>
<li><strong>More data augmentation:</strong>  Apply more aggressive data augmentation techniques or use a larger dataset.</li>
<li><strong>Adding a 'Not A Number' Class</strong> : Since the only output the model can give is number, it will classify anything to a number, adding this class and retraining model on it, will let model be able to detect when non numbers are inserted.</li>
</ul>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>